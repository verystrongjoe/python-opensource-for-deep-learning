{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어제 내용 복습\n",
    "다중분류는 왜 크로스 엔트로피를 사용하는걸까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import  Series, DataFrame\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten,Dropout\n",
    "\n",
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import  mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_train.shape\n",
    "\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(20, kernel_size=5, padding='same', \n",
    "                 input_shape=(28,28,1), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import MaxPooling2D\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides =(2,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(50, kernel_size=\n",
    "                5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 41s 844us/step - loss: 1.2295 - acc: 0.6830 - val_loss: 0.4511 - val_acc: 0.8563\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 40s 829us/step - loss: 0.3467 - acc: 0.8999 - val_loss: 0.2596 - val_acc: 0.9260\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 40s 827us/step - loss: 0.2550 - acc: 0.9253 - val_loss: 0.2081 - val_acc: 0.9393\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 40s 830us/step - loss: 0.2049 - acc: 0.9399 - val_loss: 0.1804 - val_acc: 0.9490\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 40s 830us/step - loss: 0.1719 - acc: 0.9488 - val_loss: 0.1510 - val_acc: 0.9574\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 40s 828us/step - loss: 0.1481 - acc: 0.9569 - val_loss: 0.1313 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 40s 832us/step - loss: 0.1305 - acc: 0.9612 - val_loss: 0.1165 - val_acc: 0.9669\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 40s 830us/step - loss: 0.1170 - acc: 0.9659 - val_loss: 0.1109 - val_acc: 0.9697\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 40s 831us/step - loss: 0.1073 - acc: 0.9690 - val_loss: 0.1068 - val_acc: 0.9702\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 40s 833us/step - loss: 0.0987 - acc: 0.9711 - val_loss: 0.0933 - val_acc: 0.9733\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 40s 833us/step - loss: 0.0925 - acc: 0.9728 - val_loss: 0.0937 - val_acc: 0.9721\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 40s 835us/step - loss: 0.0867 - acc: 0.9744 - val_loss: 0.0859 - val_acc: 0.9747\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 42s 866us/step - loss: 0.0819 - acc: 0.9760 - val_loss: 0.0841 - val_acc: 0.9741\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 41s 853us/step - loss: 0.0782 - acc: 0.9769 - val_loss: 0.0791 - val_acc: 0.9755\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 40s 833us/step - loss: 0.0744 - acc: 0.9781 - val_loss: 0.0776 - val_acc: 0.9761\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 40s 835us/step - loss: 0.0715 - acc: 0.9787 - val_loss: 0.0737 - val_acc: 0.9773\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 40s 834us/step - loss: 0.0689 - acc: 0.9795 - val_loss: 0.0738 - val_acc: 0.9778\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 40s 835us/step - loss: 0.0659 - acc: 0.9803 - val_loss: 0.0693 - val_acc: 0.9786\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 40s 835us/step - loss: 0.0636 - acc: 0.9811 - val_loss: 0.0694 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 40s 834us/step - loss: 0.0616 - acc: 0.9816 - val_loss: 0.0675 - val_acc: 0.9783\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=128, \n",
    "                    epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 309us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.057140451397839936, Acc.: 0.9823\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {0}, Acc.: {1}'.format(*score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave('cifar10-sample.png', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "경로 = r'C:\\Users\\student\\.keras\\datasets\\cifar-10-batches-py\\batches.meta'\n",
    "with open(경로, 'rb') as file:\n",
    "    cifar10_meta = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10_labels = cifar10_meta['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_labels[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test =  np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(\n",
    "    32, kernel_size=3, padding='same', \n",
    "    input_shape=(32, 32, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.4838 - acc: 0.1013 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 14.5075 - acc: 0.0999 - val_loss: 14.5015 - val_acc: 0.1003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train, batch_size=128, epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results = DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12166630>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6v8DjJRToba/FHAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다 깊은 층을 구성해 성능 개선\n",
    "\n",
    "conv+conv+maxpool+dropout+conv+conv+maxpool+dropout  \n",
    "dense+dropout+dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(\n",
    "    32, kernel_size=3, padding='same', activation='relu',\n",
    "    input_shape=(32, 32, 3)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(\n",
    "    32, kernel_size=3, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(\n",
    "    64, kernel_size=3, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(\n",
    "    64, kernel_size=3, padding='same', activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 143s 4ms/step - loss: 14.5126 - acc: 0.0994 - val_loss: 14.3465 - val_acc: 0.1089\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 144s 4ms/step - loss: 14.5090 - acc: 0.0998 - val_loss: 14.4805 - val_acc: 0.1016\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 141s 4ms/step - loss: 14.5139 - acc: 0.0995 - val_loss: 14.4805 - val_acc: 0.1016\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 140s 3ms/step - loss: 14.5131 - acc: 0.0996 - val_loss: 14.4805 - val_acc: 0.1016\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 194s 5ms/step - loss: 14.5135 - acc: 0.0995 - val_loss: 14.4805 - val_acc: 0.1016\n",
      "Epoch 6/10\n",
      "25472/40000 [==================>...........] - ETA: 1:07 - loss: 14.5489 - acc: 0.0973"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train, batch_size=128, epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results = DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_results[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loss: {0}, Acc.: {1}'.format(*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imsave, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "모찌 =  imread('../data/mozzi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(모찌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "모찌.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = imresize(모찌, (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsave('mozzi_32x32.png', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 보강 \n",
    "\n",
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "생성기 = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('preview'):\n",
    "    os.makedirs('preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([모찌])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flow = 생성기.flow(\n",
    "    X, batch_size=1, save_to_dir='preview',\n",
    "    save_prefix='mozzi', save_format='png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in itertools.islice(flow, 0, 20):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
